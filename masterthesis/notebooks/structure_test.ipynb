{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# add path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "# parent_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "sys.path.append(parent_dir)\n",
    "# parent_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to import the utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.custom_data_module import CustomDataModule\n",
    "from src.data.transforms import Normalise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "The image I send into the CNN is a slice of the datacube along one axis with some stride "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain trainable dataset\n",
    "\n",
    "In order to convert the numerous datacubes into a dataset I can use for training a Neural network I make use of the `Dataset` module withing the Pytorch framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CustomDataModule(redshifts=[0.0,1.0],transform=Normalise(), additional_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "----------------------\n",
      "  Gravity theories: ['Newton', 'GR']\n",
      "  Redshifts: [0.0, 1.0]\n",
      "  Stride: 2\n",
      "\n",
      "Image info (Newton:0, GR:1):\n",
      "  label: tensor([0.])\n",
      "  gravity_theory: newton\n",
      "  redshift: 0\n",
      "  seed: 0\n",
      "  axis: 0\n",
      "  slice_idx: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "data.print_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/net/hume.uio.no/uio/hume/student-u00/johanmkr/Documents/thesis/masterthesis/notebooks/structure_test.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/net/hume.uio.no/uio/hume/student-u00/johanmkr/Documents/thesis/masterthesis/notebooks/structure_test.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X, y \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mdataset[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if sample has the correct index\n",
    "def test_index(dataset, idx):\n",
    "    len_tot = len(dataset)\n",
    "    sample = dataset[idx]\n",
    "    slice_idx = sample['slice_idx']\n",
    "    axis = sample['axis']\n",
    "    seed = sample['seed']\n",
    "    redshift = sample['redshift']\n",
    "    gravity_theory = sample['gravity_theory']\n",
    "    \n",
    "    # Calculate the index the sample should have:\n",
    "    calc_idx = 0 if gravity_theory == \"newton\" else len_tot//2    \n",
    "    idx_per_redshift = len_tot//(2*dataset.nr_redshifts)\n",
    "    redshift_idx = int(np.argwhere(np.array(dataset.redshifts) == float(redshift))[0][0])\n",
    "    calc_idx += redshift_idx*idx_per_redshift\n",
    "    \n",
    "    calc_idx += seed * dataset.images_per_cube\n",
    "    \n",
    "    calc_idx += axis * dataset.images_per_axis\n",
    "    \n",
    "    calc_idx += slice_idx \n",
    "    \n",
    "    if calc_idx != idx:\n",
    "        print(f\"Error: Index {idx} does not match the calculated index {calc_idx}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3072000/3072000 [16:54:04<00:00, 50.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "ds = data.dataset\n",
    "\n",
    "\n",
    "for idx in trange(len(ds)):\n",
    "    test_index(ds, idx)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
