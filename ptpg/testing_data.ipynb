{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import h5py\n",
    "from mayavi import mlab\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# torch stuff\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as ts\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "\n",
    "# for visualisation loop:\n",
    "from matplotlib import colors\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.rcParams[\"image.origin\"] = \"lower\"\n",
    "plt.rcParams[\"image.cmap\"] = \"viridis\"\n",
    "\n",
    "# import pyvista as pv\n",
    "# mlab.init_notebook()\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "DataPath = os.path.abspath(\"\").replace(\"Summer-Sandbox23/ptpg\", \"NbodySimulation/gevolution-1.2/output/\")\n",
    "newtonPath = DataPath+\"newton/\"\n",
    "grPath = DataPath+\"gr/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files in output\n",
    "newtonFiles = os.listdir(newtonPath)\n",
    "grFiles = os.listdir(grPath)\n",
    "\n",
    "print(newtonFiles)\n",
    "print(grFiles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract datasets with .h5 formats\n",
    "def Extracth5Specifics(filename:str) -> np.ndarray:\n",
    "    h5File = h5py.File(filename, \"r\")\n",
    "    dataset = h5File[\"data\"][()]\n",
    "    h5File.close()\n",
    "    return dataset\n",
    "\n",
    "def Extracth5Data(abspath:str) -> np.ndarray or list[np.ndarray]:\n",
    "    Files = os.listdir(abspath)\n",
    "    h5Files = [abspath+name for name in Files if \".h5\" in name]\n",
    "    if len(h5Files) > 1:\n",
    "        datasets = []\n",
    "        for filename in h5Files:\n",
    "            datasets.append(Extracth5Specifics(filename))\n",
    "        return datasets\n",
    "    else:\n",
    "        return Extracth5Specifics(h5Files[0])\n",
    "\n",
    "newtonCube = Extracth5Data(newtonPath)\n",
    "grCube = Extracth5Data(grPath)\n",
    "grCube = grCube + 1000000 * grCube\n",
    "print(f\"Dimension of newton cube: {np.shape(newtonCube)}\")\n",
    "print(f\"Dimension of gr cube: {np.shape(grCube)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SliceDataCube(data:np.ndarray, axis:int, index:int or list or tuple) -> np.ndarray:\n",
    "    slices = [slice(None)] * data.ndim\n",
    "    if isinstance(index, int):\n",
    "        slices[axis] = index\n",
    "    else:\n",
    "        slices[axis] = slice(index[0], index[1])\n",
    "    return data[tuple(slices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(SliceDataCube(newtonCube, axis=1, index=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VisualiseSlice(cube:np.ndarray, name:str=None, axis:int=None, difference:bool=False):\n",
    "    fig, ax = plt.subplots(figsize=(7.5,7.5))\n",
    "    ims = []\n",
    "    axis = axis if axis is not None else 0\n",
    "    for i in range(cube.shape[axis]):\n",
    "        image = SliceDataCube(cube, axis, i)\n",
    "        temp_min = np.percentile(image, 1)\n",
    "        temp_max = np.percentile(image, 99)\n",
    "        # if not difference:\n",
    "        #     temp_norm = colors.TwoSlopeNorm(vmin=temp_min, vcenter=0, vmax=temp_max)\n",
    "        #     temp = [ax.imshow(image, norm=temp_norm)]\n",
    "        # else:\n",
    "        temp = [ax.imshow(image, vmin=temp_min, vmax=temp_max)]\n",
    "        ims.append(temp)\n",
    "    # name = f\"{cube=}\".split(\"=\")[0]\n",
    "    ax.set_title(f\"Visualising {name if name is not None else ''} across axis: {axis}\")\n",
    "    norm = colors.Normalize(vmin=temp_min, vmax=temp_max)\n",
    "    sm = cm.ScalarMappable(cmap='viridis', norm=norm)\n",
    "    sm.set_array([])\n",
    "    fig.colorbar(sm, ax=ax)\n",
    "    fig.tight_layout()\n",
    "    anim = ArtistAnimation(fig, ims, interval=50, blit=True)\n",
    "    plt.close(fig)\n",
    "    return anim\n",
    "\n",
    "def VisualiseDifference(cube1:np.ndarray, cube2:np.ndarray, axis:int=None, absolute:bool=True):\n",
    "    cube = np.abs(cube1-cube2) if absolute else cube1-cube2\n",
    "    return VisualiseSlice(cube, name=\"difference\", axis=axis, difference=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtonAnim = VisualiseSlice(newtonCube, name=\"gr\", axis=2)\n",
    "HTML(newtonAnim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffAnim = VisualiseDifference(newtonCube, grCube, axis=0)\n",
    "HTML(diffAnim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class\n",
    "\n",
    "class TestCubes(Dataset):\n",
    "    def __init__(self, newtonCube, grCube, stride=1, transform=None, additionalInfo=False):\n",
    "        self.newtonCube = newtonCube\n",
    "        self.grCube = grCube\n",
    "        self.stride=stride\n",
    "        self.length = self.__len__()\n",
    "        self.halflength = int(self.length/2.)\n",
    "        self.transform = transform\n",
    "        self.additionalInfo = additionalInfo\n",
    "\n",
    "    def __len__(self):\n",
    "        newtonShape = self.newtonCube.shape\n",
    "        grShape = self.grCube.shape\n",
    "        newtonLength = 0\n",
    "        grLength = 0\n",
    "        for i in range(len(newtonShape)):\n",
    "            newtonLength += newtonShape[i]\n",
    "            grLength += grShape[i]\n",
    "        return int((newtonLength+grLength)/self.stride)\n",
    "\n",
    "    def _getSlice(self, data:np.ndarray, axis:int, index:int or list or tuple):\n",
    "        slices = [slice(None)] * data.ndim\n",
    "        if isinstance(index, int):\n",
    "            slices[axis] = index\n",
    "        else:\n",
    "            slices[axis] = slice(index[0], index[1])\n",
    "        return data[tuple(slices)]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        NEWTON = idx < self.halflength\n",
    "        if not NEWTON:\n",
    "            idx = idx-self.halflength\n",
    "        axis = idx // self.newtonCube.shape[0] #only works for cubic cubes and stride 1 for now, should be easy to improve\n",
    "        index = idx % self.newtonCube.shape[0]\n",
    "        if NEWTON:\n",
    "            slice_data = self._getSlice(self.newtonCube, axis, index)\n",
    "            label = torch.tensor([0.0], dtype=torch.float32)\n",
    "        else:\n",
    "            slice_data = self._getSlice(self.grCube, axis, index)\n",
    "            label = torch.tensor([1.0], dtype=torch.float32)\n",
    "        if self.stride != 1:\n",
    "            sample = {\"image\": torch.tensor(slice_data, dtype=torch.float32), \"label\": label}\n",
    "        else:\n",
    "            sample = {\"image\": torch.tensor(slice_data, dtype=torch.float32).unsqueeze(0), \"label\": label}\n",
    "\n",
    "        if self.additionalInfo:\n",
    "            sample[\"axis\"] = axis\n",
    "            sample[\"index\"] = index\n",
    "        if self.transform:\n",
    "            # toBeNormalized = sample[\"image\"]\n",
    "            # Normalized = self.transform(toBeNormalized)\n",
    "            # sample[\"image\"] = Normalized\n",
    "            sample[\"image\"] = (sample[\"image\"]-torch.mean(sample[\"image\"]))/torch.std(sample[\"image\"])\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def __str__(self, idx=None):\n",
    "        returnString = \"Dataset info:\\n----------------------\\n\"\n",
    "        returnString += f\"  Newton cube size: {self.newtonCube.shape}\\n\"\n",
    "        returnString += f\"  GR cube size: {self.grCube.shape}\\n\"\n",
    "        returnString += f\"  Stride: {self.stride}\\n\"\n",
    "        return returnString\n",
    "\n",
    "    def printImage(self, idx):\n",
    "        returnString = \"\"\n",
    "        sample = self.__getitem__(idx)\n",
    "        image = sample[\"image\"]\n",
    "        returnString += f\"Image info (Newton:0, GR:1):\\n\"\n",
    "        for key, val in sample.items():\n",
    "            if key != \"image\":\n",
    "                returnString += f\"  {key}: {val}\\n\"\n",
    "        returnString += \"Basic statistics:\\n\"\n",
    "        basicStat = {\n",
    "            \"mean\": torch.mean(image),\n",
    "            \"min\": torch.min(image),\n",
    "            \"max\": torch.max(image),\n",
    "            \"std\": torch.std(image),\n",
    "            \"median\": torch.median(image)\n",
    "        }\n",
    "        for key, val in basicStat.items():\n",
    "            returnString += f\"  {key}: {val}\\n\" \n",
    "        returnString += \"\\n\"\n",
    "        return returnString\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = TestCubes(newtonCube, grCube, transform=False, additionalInfo=True)\n",
    "print(L.printImage(64*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[train, val, test] = random_split(L, [0.7,0.2,0.1], generator=generator1)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=32)\n",
    "val_loader = DataLoader(val, batch_size=32)\n",
    "test_loader = DataLoader(test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural network\n",
    "\n",
    "class SkeletonCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SkeletonCNN, self).__init__()\n",
    "        ### LAYER 1 (Convolutional) ### (1, 64, 64) -> (64, 64, 64)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(3,3), stride=1, padding=1),       # (1, 64, 64) -> (64, 64, 64)\n",
    "            nn.ReLU(),                                                      # -\n",
    "            nn.Dropout(0.25),                                                # -\n",
    "        )\n",
    "        \n",
    "        ### LAYER 2 (Convolutional) ### (64, 64, 64) -> (32, 16, 16)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=(3,3), stride=1, padding=1),      # (64, 64, 64) -> (32, 64, 64)\n",
    "            nn.ReLU(),                                                      # - \n",
    "            nn.MaxPool2d(kernel_size=(4,4)),                                # (32, 64, 64) -> (32, 16, 16)\n",
    "        )\n",
    "\n",
    "        ### FLATTENING ###  (32, 16, 16) -> (8192)\n",
    "        # self.flat = nn.Flatten()\n",
    "\n",
    "        ### LAYER 3 (Fully connected) ###   (8192) -> (256)\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Flatten(),                                                   # (32, 16, 16) -> (8192)\n",
    "            nn.Linear(int(32*16*16), 256),                                  # (8192) -> (256)\n",
    "            nn.ReLU(),                                                      # -\n",
    "            nn.Dropout(0.25),                                               # -\n",
    "        )\n",
    "\n",
    "        ### LAYER 4 (Fully connected) ###\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(256, 16),                                             # (256) -> (16)\n",
    "            nn.ReLU(),                                                      # -\n",
    "            nn.Dropout(0.25),                                               # -\n",
    "        )\n",
    "\n",
    "        ### LAYER 5 (Output) ###\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(16, 1),                                               # (16) -> (2)\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        # List of layers\n",
    "        self.layers = [self.layer1, self.layer2, self.layer3, self.layer4]\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return self.output(X)\n",
    "    \n",
    "    def printSummary(self, input:tuple=(1,64,64)):\n",
    "        return summary(self, input_size=input)\n",
    "\n",
    "from torchsummary import summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SkeletonCNN()\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.printSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    for object in train_loader:\n",
    "        inputs = object[\"image\"]\n",
    "        labels = object[\"label\"]\n",
    "        y_pred = model(inputs)\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        # print(y_pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    acc = 0\n",
    "    count = 0\n",
    "    tol = 1e-7\n",
    "    for object in val_loader:\n",
    "        inputs = object[\"image\"]\n",
    "        labels = object[\"label\"]\n",
    "        y_pred = model(inputs)\n",
    "        acc += (torch.abs(torch.round(y_pred) - labels)<tol).float().sum()\n",
    "        count += len(labels)\n",
    "    acc /= count\n",
    "    # print(f\"Epoch: {epoch}, Loss: {loss.item():.4f}, Acc: {acc*100:.2f} %\")\n",
    "    print(f\"Epoch: [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}, Acc: {acc*100:.2f} %\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing: \n",
    "correct = 0\n",
    "count = 0\n",
    "tol = 1e-7\n",
    "for object in test_loader:\n",
    "    inputs = object[\"image\"]\n",
    "    labels = object[\"label\"]\n",
    "    y_pred = model(inputs)\n",
    "    correct += (torch.abs(torch.round(y_pred) - labels)<tol).float().sum()\n",
    "    count += len(labels)\n",
    "acc = correct / count\n",
    "\n",
    "print(f\"Correct: [{correct} / {count}] giving accuracy of {acc*100:.2f} %\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
